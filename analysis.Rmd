---
title: "Data analysis"
output: html_notebook
---



```{r setup}
library(tidyverse)
library(readr)
library(lubridate)
library(jagsUI)
library(bayesplot)
library(rstan)
library(rstanarm)
library(loo)
library(flextable)

compute.LOOIC <- function(loglik.mat, data.vector, MCMC.params){
  n.per.chain <- (MCMC.params$n.samples - MCMC.params$n.burnin)/MCMC.params$n.thin
  
  #loglik.vec <- as.vector(loglik)
  
  # each column corresponds to a data point and rows are MCMC samples
  #loglik.mat <- matrix(loglik.vec, nrow = n.per.chain * MCMC.params$n.chains)
  # take out the columns that correspond to missing data points
  loglik.mat <- loglik.mat[, !is.na(data.vector)]
  
  Reff <- relative_eff(exp(loglik.mat),
                       chain_id = rep(1:MCMC.params$n.chains,
                                      each = n.per.chain),
                       cores = 4)
  
  loo.out <- rstanarm::loo(loglik.mat, 
                           r_eff = Reff, 
                           cores = 4, k_threshold = 0.7)
  
  out.list <- list(Reff = Reff,
                   loo.out = loo.out)
  
  return(out.list)  
}

```

Get data and make numerical months and numerical seasons. Each "year" has to start from December the year before to make sense out of data.

```{r}
col.def <- cols(Year = col_integer(),
                Season = col_character(),
                Month = col_character(),
                Station = col_integer(),
                Counts = col_integer())

# month.name is a built-in variable
data.0 <- read_csv(file = "data/sightings-1.csv", col_types = col.def) %>%
  mutate(Year_d = Year - min(Year) + 1,
         Month_d = match(Month, month.name),
         Season_d = match(Season, c("Winter", "Spring", "Summer", "Fall")),
         Year_idx = ifelse(Month_d < 12, Year_d, Year_d+1)) 


```


Models may include the abundance ($N$), sighting probability ($\theta_{y,m,i}$, where $y$ is year, $m$ is month, $i$ is station), proportions that distribute $N$ among stations ($p_{y,m,i}$, and observed counts ($n_{y,m,i}$). The objective is to find differences in counts among stations. I'm going to assume that the sighting probability among stations, months, and years are constant, because people were shuffled around among stations (assuming...). So, $\theta_{y,m,i} = \theta$  $\forall$ $y, m, i$. We may include year specific sighting probability, considering that people might increased their sighting skill over the years ($\theta_{y}$).

$$ n_{y,m,i} \sim f(p_{y,m,i} \times N_{y} \times \theta) $$

Because $n$ are counts, Poisson may be the first candidate model.

It is unclear what abundance the parameter $N$ represents. Because turtles can swim among stations during a survey, it is not the number of turtles. Because N is distributed among stations, it has to represent the number of surfacings. However... if ps don't sum to 1 among stations during a survey day, I'm not sure what this N is. I think the next section with the multinomial distribution makes more sense... 

```{r}
MCMC.params <- list(n.chains = 5,
                    n.samples = 100000,
                    n.burnin = 80000,
                    n.thin = 5)

jags.data <- list(n = data.0$Counts,
                  log.n = log(data.0$Counts + 1),
                  n.line = nrow(data.0),
                  n.year = max(data.0$Year_d),
                  Year = data.0$Year_d,
                  Month = data.0$Month_d,
                  Station = data.0$Station,
                  Season = data.0$Season_d,
                  n.season = 4,
                  Nmin = 0, Nmax = 250)

jags.params <- c("n", "theta", "p", "N", "sd.n", 
                 "deviance", "loglik")

model.files <- data.frame(model.name = c("Pois-1", "Pois-2", "Pois-3", "Pois-4", "Pois-5", "Pois-6",
                                         "Norm-1", "Norm-2", "Norm-3", "Norm-4", "Norm-5", "Norm-6"),
  model.file = c("models/model_Pois_p_year_month_station_N_year_season.txt",
                 "models/model_Pois_p_year_month_station_N_year.txt",
                 "models/model_Pois_p_year_station_N_year_season.txt",
                 "models/model_Pois_p_year_station_N_year.txt",
                 "models/model_Pois_p_station_N_year_season.txt",
                 "models/model_Pois_p_station_N_year.txt",
                 "models/model_logN_p_year_month_station_N_year_season.txt",
                 "models/model_logN_p_year_month_station_N_year.txt",
                 "models/model_logN_p_year_station_N_year_season.txt",
                 "models/model_logN_p_year_station_N_year.txt",
                 "models/model_logN_p_station_N_year_season.txt",
                 "models/model_logN_p_station_N_year.txt"))


jags.fit <- list()
LOOIC.out <- list()
#out.file.name <- "RData/jags_out.rds"

k <- 7
start.time <- now()
for (k in 1:nrow(model.files)){
  out.file.name <-  paste0("RData/jags_out_", model.files[k, "model.name"], ".rds")
  
  
  if (!file.exists(out.file.name)){
    start.time <- now()  
    jags.fit[[k]] <- jags(jags.data,
                          inits = NULL,
                          parameters.to.save= jags.params,
                          model.file = model.files[k, "model.file"],
                          n.chains = MCMC.params$n.chains,
                          n.burnin = MCMC.params$n.burnin,
                          n.thin = MCMC.params$n.thin,
                          n.iter = MCMC.params$n.samples,
                          DIC = T, parallel=T)
    
    LOOIC.out[[k]] <- compute.LOOIC(loglik.mat = jags.fit[[k]]$sims.list$loglik,
                                    data.vector = jags.data$n,
                                    MCMC.params = MCMC.params)
    
    end.time <- now()
    
    out.list <- list(model.names = model.files[k, "model.file"],
                     jm.out = jags.fit[[k]],
                     LOOIC.out = LOOIC.out[[k]],
                     jags.data = jags.data,
                     jags.params = jags.params,
                     MCMC.params = MCMC.params,
                     run.date = Sys.Date(),
                     system = Sys.info(),
                     run.time = end.time - start.time)
    
    saveRDS(out.list, file = out.file.name)    
  } else {
    
    out.list <- readRDS(out.file.name)
    
    jags.fit[[k]] <- out.list$jm.out
    LOOIC.out[[k]] <- out.list$LOOIC.out
  }
}

LOOIC.df <- data.frame(model = model.files$model.name,
                       DIC = lapply(jags.fit, 
                                    FUN = function(x) x$DIC) %>% 
                         unlist(),
                       Rhat = lapply(jags.fit, 
                                     FUN = function(x) x$Rhat %>% 
                                       unlist() %>% 
                                       max(na.rm = T)) %>% 
                         unlist(),
                       LOOIC = lapply(LOOIC.out, 
                                      FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>% 
                         unlist(),
                       max.pareto = lapply(LOOIC.out, 
                                           FUN = function(x) x$loo.out$diagnostics$pareto_k %>% 
                                             max()) %>%
                         unlist()) %>%
  mutate(dDIC = DIC - min(DIC),
         dLOOIC = LOOIC - min(LOOIC)) %>%
  select(-c("DIC", "LOOIC")) %>%
  arrange(dLOOIC) %>% 
  select(model, Rhat, dDIC, dLOOIC, max.pareto)
  


```


Interesting results came back when fitting these `r length(model.files)` models to the data \@ref(tab:LOOIC.table). 


```{r LOOIC.table, echo=FALSE, warning=FALSE}

flextable(LOOIC.df) %>% 
  #hline(i = (nrow(ratio.summary.table)-1)) %>%
  set_caption(paste0("Comparison of how models fit to the data. Rhat indicates the conversion of Markov chain Monte Carlo, where Rhat < 1.1 is considered to be acceptable. dDIC indicates the difference in deviance information criteria (DIC) value from the smallest DIC value, where the model with smallest DIC is considered best. dLOOIC indicates leave-one-out information criteria, where the smaller values indicate better models. max.pareto indicates the maximum value of Pareto k statistic, which is an index of model fit. Values of Pareto k statistics less than 0.5 are considered acceptable. Values greater than 0.7 indicate ill fit of the model.")) %>%
  set_table_properties(width = 0.5, layout = "autofit") %>%
  colformat_double(j = c("Rhat", "dDIC", "dLOOIC", "max.pareto"), digits = 2)

```


The best model appears to be log(n) with station-specific sighting probability and year- and season-specific total abundance. This does make sense. 

```{r}
best.model.name <- LOOIC.df[1,"model"]
best.model.out <- jags.fit[[which(model.files$model.name == best.model.name)]]

# Get rid of the big object
rm(list = "out.list")

# check conversions visually
mcmc_trace(best.model.out$samples, pars = c("p[1]", "p[2]", "p[3]", "p[4]",
                                            "p[5]", "p[6]", "p[7]", "p[8]",
                                            "p[9]", "p[10]"))

```

```{r}
mcmc_trace(best.model.out$samples, pars = c("N[1,1]", "N[2,1]", "N[3,1]", "N[4,1]",
                                            "N[5,1]", "N[6,1]", "N[7,1]", "N[8,1]",
                                            "N[9,1]"))

```


```{r}
mcmc_trace(best.model.out$samples, pars = c("N[1,2]", "N[2,2]", "N[3,2]", "N[4,2]",
                                            "N[5,2]", "N[6,2]", "N[7,2]", "N[8,2]",
                                            "N[9,2]"))

```


```{r}
mcmc_trace(best.model.out$samples, pars = c("N[1,3]", "N[2,3]", "N[3,3]", "N[4,3]",
                                            "N[5,3]", "N[6,3]", "N[7,3]", "N[8,3]",
                                            "N[9,3]"))

```


```{r}
mcmc_trace(best.model.out$samples, pars = c("N[1,4]", "N[2,4]", "N[3,4]", "N[4,4]",
                                            "N[5,4]", "N[6,4]", "N[7,4]", "N[8,4]",
                                            "N[9,4]"))

```


Most look okay but some are pushed against the upper limit. Probably because of lack of data. 

```{r}

mcmc_dens(best.model.out$samples, pars = c("N[1,2]", "N[5,3]", "N[5,4]", "N[6,1]",
                                            "N[6,3]", "N[7,3]", "N[7,4]"))

```


Or.... use multinomial

In this approach, the N parameter ($N_{k}$, where k is the index of all sampling days) is considered as the total number of surfacings during a survey period. The total number ($N_{k}$) is distributed among 10 stations, which is modeled with the multinomial distribution.

$$ \textbf{n}_{k} \sim multi(N_{k}, \textbf{p}_{k})$$

$\textbf{n}_{k}$ is a vector of length 10, which contains observed counts at 10 stations on the $k$-th day of observation. $N_k$ is the sum of all observed counts on the same day ($N_k = \sum_{k=1}^{k=10} n_k$.    

```{r multinomial, echo=FALSE, message=FALSE}
# restart with everything removed
rm(list=ls())
MCMC.params <- list(n.chains = 5,
                    n.samples = 100000,
                    n.burnin = 80000,
                    n.thin = 5)

compute.LOOIC <- function(loglik.mat, MCMC.params){
  n.per.chain <- (MCMC.params$n.samples - MCMC.params$n.burnin)/MCMC.params$n.thin
  
  #loglik.vec <- as.vector(loglik)
  
  Reff <- relative_eff(exp(loglik.mat),
                       chain_id = rep(1:MCMC.params$n.chains,
                                      each = n.per.chain),
                       cores = 4)
  
  loo.out <- rstanarm::loo(loglik.mat, 
                           r_eff = Reff, 
                           cores = 4, k_threshold = 0.7)
  
  out.list <- list(Reff = Reff,
                   loo.out = loo.out)
  
  return(out.list)  
}

col.def <- cols(Date = col_date(format = "%m/%d/%Y"),
                Station01 = col_integer(),
                Station02 = col_integer(),
                Station03 = col_integer(),
                Station04 = col_integer(),
                Station05 = col_integer(),
                Station06 = col_integer(),
                Station07 = col_integer(),
                Station08 = col_integer(),
                Station09 = col_integer(),
                Station10 = col_integer())

# month.name is a built-in variable
data.1 <- read_csv(file = "data/sightings.csv", col_types = col.def) %>%
  mutate(Month = month(Date),
         Season_d = ifelse(Month == 1 | Month == 2 | Month == 12, 1,
                           ifelse(Month > 2 & Month < 6, 2,
                                  ifelse(Month > 5 & Month < 9, 3, 4))),
         Year_d = year(Date) - min(year(Date)) + 1,
         Year_idx = ifelse(Month < 12, Year_d, Year_d + 1),
         Year_Season_d = (Year_idx - 1) * 4 + Season_d,
         Year_Month_d = (Year_d - 1) * 12 + Month) %>% 
  na.omit()
  
data.1 %>% select(starts_with("Station")) %>%
  as.matrix() -> Counts


jags.data <- list(n = Counts,
                  N = rowSums(Counts),
                  n.day = nrow(Counts),
                  n.year = max(data.1$Year_idx),
                  Year = data.1$Year_idx,
                  Season = data.1$Season_d,
                  Year.Season = data.1$Year_Season_d,
                  Year.Month = seq(1, nrow(Counts)),
                  max.Year.Season = length(data.1$Year_Season_d),
                  max.Year.Month = length(data.1$Year_Month_d),
                  alpha = rep(1, times = 10))

jags.params <- c("theta", "p", "N1",  
                 "deviance", "loglik")

model.files <- data.frame(model.name = c("Multi-1", "Multi-2", "Multi-3", "Multi-4", "Multi-5"),
  model.file = c("models/model_multinomial.txt",
                 "models/model_multinomial_p_year.txt",
                 "models/model_multinomial_p_season.txt",
                 "models/model_multinomial_p_year_season.txt",
                 "models/model_multinomial_p_year_Month.txt"))


jags.fit.multi <- list()
LOOIC.out.multi <- list()
#out.file.name <- "RData/jags_out.rds"

k <- 7

for (k in 1:nrow(model.files)){
  out.file.name <-  paste0("RData/jags_out_", model.files[k, "model.name"], ".rds")
  

  if (!file.exists(out.file.name)){
    start.time <- now()  
    jags.fit.multi[[k]] <- jags(jags.data,
                          inits = NULL,
                          parameters.to.save= jags.params,
                          model.file = model.files[k, "model.file"],
                          n.chains = MCMC.params$n.chains,
                          n.burnin = MCMC.params$n.burnin,
                          n.thin = MCMC.params$n.thin,
                          n.iter = MCMC.params$n.samples,
                          DIC = T, parallel=T)
    
    LOOIC.out.multi[[k]] <- compute.LOOIC(loglik.mat = jags.fit.multi[[k]]$sims.list$loglik,
                                    MCMC.params = MCMC.params)
    
    end.time <- now()
    
    out.list <- list(model.names = model.files[k, "model.file"],
                     jm.out = jags.fit.multi[[k]],
                     LOOIC.out = LOOIC.out.multi[[k]],
                     jags.data = jags.data,
                     jags.params = jags.params,
                     MCMC.params = MCMC.params,
                     run.date = Sys.Date(),
                     system = Sys.info(),
                     run.time = end.time - start.time)
    
    saveRDS(out.list, file = out.file.name)    
  } else {
    
    out.list <- readRDS(out.file.name)
    
    jags.fit.multi[[k]] <- out.list$jm.out
    LOOIC.out.multi[[k]] <- out.list$LOOIC.out
  }
}

LOOIC.multi.df <- data.frame(model = model.files$model.name,
                       DIC = lapply(jags.fit.multi, 
                                    FUN = function(x) x$DIC) %>% 
                         unlist(),
                       Rhat = lapply(jags.fit.multi, 
                                     FUN = function(x) x$Rhat %>% 
                                       unlist() %>% 
                                       max(na.rm = T)) %>% 
                         unlist(),
                       LOOIC = lapply(LOOIC.out.multi, 
                                      FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>% 
                         unlist(),
                       max.pareto = lapply(LOOIC.out.multi, 
                                           FUN = function(x) x$loo.out$diagnostics$pareto_k %>% 
                                             max()) %>%
                         unlist()) %>%
  mutate(dDIC = DIC - min(DIC),
         dLOOIC = LOOIC - min(LOOIC)) %>%
  select(-c("DIC", "LOOIC")) %>%
  arrange(dLOOIC) %>% 
  select(model, Rhat, dDIC, dLOOIC, max.pareto)
  

# 
# mcmc_trace(jm$samples, pars = c("p[1,1]", "p[1,2]", "p[1,3]", "p[1,4]",
#                                 "p[1,5]", "p[1,6]", "p[1,7]", "p[1,8]",
#                                 "p[1,9]", "p[1,10]"))

```

```{r}
flextable(LOOIC.multi.df) %>% 
  #hline(i = (nrow(ratio.summary.table)-1)) %>%
  set_caption(paste0("Comparison of how models fit to the data when using the multinomial distribution. Rhat indicates the conversion of Markov chain Monte Carlo, where Rhat < 1.1 is considered to be acceptable. dDIC indicates the difference in deviance information criteria (DIC) value from the smallest DIC value, where the model with smallest DIC is considered best. dLOOIC indicates leave-one-out information criteria, where the smaller values indicate better models. max.pareto indicates the maximum value of Pareto k statistic, which is an index of model fit. Values of Pareto k statistics less than 0.5 are considered acceptable. Values greater than 0.7 indicate ill fit of the model.")) %>%
  set_table_properties(width = 0.5, layout = "autofit") %>%
  colformat_double(j = c("Rhat", "dDIC", "dLOOIC", "max.pareto"), digits = 2)

```


Pareto-k statistics are too high. I'm thinking it too much? Perhaps, go ahead and use just DIC and use the Multi-5 model (Year-Month model) to do inference.

```{r Multi-5, echo=FALSE}

best.model.name <- "Multi-5"
best.model.out <- jags.fit.multi[[which(model.files$model.name == best.model.name)]]

# Get rid of the big object
rm(list = "out.list")

# check conversions visually
mcmc_trace(best.model.out$samples, pars = c("p[1,1]", "p[1,2]", "p[1,3]", "p[1,4]",
                                            "p[1,5]", "p[1,6]", "p[1,7]", "p[1,8]",
                                            "p[1,9]", "p[1,10]"))


```

Convergence seems to be okay. 

```{r}

p.idx.df <- data.frame(Year_idx = year(data.1$Date),
                       Month = data.1$Month) 

all.ps.mean <- best.model.out$mean$p 
colnames(all.ps.mean) <- c("S01", "S02", "S03", "S04", "S05",
                           "S06", "S07", "S08", "S09", "S10")

all.ps.mean.long <- cbind(p.idx.df, all.ps.mean) %>%
  pivot_longer(cols = starts_with("S"),
               names_to = "Station") 

ggplot(all.ps.mean.long) +
  geom_tile(aes(x = Station, y = Month, fill = value)) +
  scale_fill_gradient(low="white", high="black") +
  scale_y_continuous(breaks = c(1,3,5,7,9,11))+
  theme(axis.text.x =element_text(angle = 90, vjust = 0.5),
        legend.position = "none") +
  #labs(fill = "Mean") +
  facet_wrap(~Year_idx)

# plots_year <- list()
# 
# for (k in 1:jags.data$n.year){
#   plots_year[[k]] <- ggplot(all.ps.mean.long %>% 
#                               filter(Year_idx == k)) +
#     geom_tile(aes(y = Month, x = Station, fill = value))
#   
# }
ggsave(filename = "figures/Sighting_proportions.png",
       dpi = 600, device = "png")
  
```



